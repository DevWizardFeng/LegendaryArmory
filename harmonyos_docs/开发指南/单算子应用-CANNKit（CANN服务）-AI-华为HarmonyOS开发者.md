<h1 _ngcontent-cov-c119="" class="doc-title ng-star-inserted" title="单算子应用"> 单算子应用 </h1>

<div _ngcontent-cov-c106="" auitextselectionexpansion="" class="markdown-body ng-star-inserted" style="position: relative;"> <div><div class="tiledSection"><h2 id="section1817194572017">概述<i class="anchor-icon anchor-icon-link" anchorid="section1817194572017" tips="复制节点链接"></i></h2><p>CANN Kit提供独立的算子创建和计算通路，三方框架可以在模型加载、推理过程中，将卷积、深度卷积等算子通过单算子对接的方式迁移至NPU，经过硬件平台的加速计算，与整网模式对比灵活度更高，相比于整网CPU计算性能更优。</p> <p><span><img height="285.285" originheight="4063" originwidth="7444" src="https://alliance-communityfile-drcn.dbankcdn.com/FileServer/getFile/cmtyPub/011/111/111/0000000000011111111.20251211114227.31948851602848909797790268378731:50001231000000:2800:EC83049F3F8B98C4AC21D3C7F40E6F3502D8382253856165ADD7A65D647D9781.jpg" title="点击放大" width="523.6875"></span></p> <p>以下为单算子Tensor创建，单算子执行器创建、加载、执行接口，接口使用请参见<a href="/consumer/cn/doc/harmonyos-guides/cannkit-single-operator-application#section1373122216206">开发步骤</a>。如要使用更丰富的设置和查询接口，请参见<a href="https://developer.huawei.com/consumer/cn/doc/harmonyos-references/cannkit" target="_blank">API参考</a>。</p>  <div class="tablenoborder"><div class="tbBox"><table class="layoutFixed idpTab"><caption><b>表1 </b>单算子接口及功能介绍</caption><thead><tr><th align="left" class="cellrowborder" id="mcps1.3.1.5.2.3.1.1" valign="top" width="50%"><p>接口名</p> </th> <th align="left" class="cellrowborder" id="mcps1.3.1.5.2.3.1.2" valign="top" width="50%"><p>描述</p> </th> </tr> </thead> <tbody><tr><td class="cellrowborder" valign="top" width="50%"><p>HiAI_SingleOpTensorDesc * HMS_HiAISingleOpTensorDesc_Create (const int64_t *dims, size_t dimNum, HiAI_SingleOpDataType dataType, HiAI_SingleOpFormat format, bool isVirtual);</p> </td> <td class="cellrowborder" valign="top" width="50%"><p>创建HiAI_SingleOpTensorDesc对象。</p> </td> </tr> <tr><td class="cellrowborder" valign="top" width="50%"><p>void HMS_HiAISingleOpTensorDesc_Destroy (HiAI_SingleOpTensorDesc **tensorDesc);</p> </td> <td class="cellrowborder" valign="top" width="50%"><p>释放HiAI_SingleOpTensorDesc对象。</p> </td> </tr> <tr><td class="cellrowborder" valign="top" width="50%"><p>HiAI_SingleOpBuffer * HMS_HiAISingleOpBuffer_Create (size_t dataSize);</p> </td> <td class="cellrowborder" valign="top" width="50%"><p>按照指定的内存大小创建HiAI_SingleOpBuffer对象。</p> </td> </tr> <tr><td class="cellrowborder" valign="top" width="50%"><p>size_t HMS_HiAISingleOpBuffer_GetSize (const HiAI_SingleOpBuffer *buffer);</p> </td> <td class="cellrowborder" valign="top" width="50%"><p>查询HiAI_SingleOpBuffer的字节大小。</p> </td> </tr> <tr><td class="cellrowborder" valign="top" width="50%"><p>void * HMS_HiAISingleOpBuffer_GetData (const HiAI_SingleOpBuffer *buffer);</p> </td> <td class="cellrowborder" valign="top" width="50%"><p>查询HiAI_SingleOpBuffer的内存地址。</p> </td> </tr> <tr><td class="cellrowborder" valign="top" width="50%"><p>OH_NN_ReturnCode HMS_HiAISingleOpBuffer_Destroy (HiAI_SingleOpBuffer **buffer);</p> </td> <td class="cellrowborder" valign="top" width="50%"><p>释放HiAI_SingleOpBuffer对象。</p> </td> </tr> <tr><td class="cellrowborder" valign="top" width="50%"><p>HiAI_SingleOpTensor * HMS_HiAISingleOpTensor_CreateFromTensorDesc (const HiAI_SingleOpTensorDesc *desc);</p> </td> <td class="cellrowborder" valign="top" width="50%"><p>根据HiAI_SingleOpTensorDesc创建HiAI_SingleOpTensor对象。</p> </td> </tr> <tr><td class="cellrowborder" valign="top" width="50%"><p>HiAI_SingleOpTensor * HMS_HiAISingleOpTensor_CreateFromConst (const HiAI_SingleOpTensorDesc *desc, void *data, size_t dataSize);</p> </td> <td class="cellrowborder" valign="top" width="50%"><p>根据HiAI_SingleOpTensorDesc、常量数据（如卷积权重、偏置等）的内存地址和数据大小创建HiAI_SingleOpTensor对象。</p> </td> </tr> <tr><td class="cellrowborder" valign="top" width="50%"><p>HiAI_SingleOpTensorDesc * HMS_HiAISingleOpTensor_GetTensorDesc (const HiAI_SingleOpTensor *tensor);</p> </td> <td class="cellrowborder" valign="top" width="50%"><p>获取HiAI_SingleOpTensor的Tensor描述。</p> </td> </tr> <tr><td class="cellrowborder" valign="top" width="50%"><p>HiAI_SingleOpBuffer * HMS_HiAISingleOpTensor_GetBuffer (const HiAI_SingleOpTensor *tensor);</p> </td> <td class="cellrowborder" valign="top" width="50%"><p>获取HiAI_SingleOpTensor的Buffer。</p> </td> </tr> <tr><td class="cellrowborder" valign="top" width="50%"><p>OH_NN_ReturnCode HMS_HiAISingleOpTensor_Destroy (HiAI_SingleOpTensor **tensor);</p> </td> <td class="cellrowborder" valign="top" width="50%"><p>释放HiAI_SingleOpTensor对象。</p> </td> </tr> <tr><td class="cellrowborder" valign="top" width="50%"><p>HiAI_SingleOpOptions * HMS_HiAISingleOpOptions_Create (void);</p> </td> <td class="cellrowborder" valign="top" width="50%"><p>创建HiAI_SingleOpOptions对象。</p> </td> </tr> <tr><td class="cellrowborder" valign="top" width="50%"><p>void HMS_HiAISingleOpOptions_Destroy (HiAI_SingleOpOptions **options);</p> </td> <td class="cellrowborder" valign="top" width="50%"><p>释放HiAI_SingleOpOptions对象。</p> </td> </tr> <tr><td class="cellrowborder" valign="top" width="50%"><p>HiAI_SingleOpDescriptor* HMS_HiAISingleOpDescriptor_CreateConvolution(HiAISingleOpDescriptor_ConvolutionParam param);</p> </td> <td class="cellrowborder" valign="top" width="50%"><p>创建卷积类（普通卷积、转置卷积、深度卷积）的描述符对象。</p> </td> </tr> <tr><td class="cellrowborder" valign="top" width="50%"><p>void HMS_HiAISingleOpDescriptor_Destroy (HiAI_SingleOpDescriptor **opDesc);</p> </td> <td class="cellrowborder" valign="top" width="50%"><p>释放HiAI_SingleOpDescriptor对象。</p> </td> </tr> <tr><td class="cellrowborder" valign="top" width="50%"><p>HiAI_SingleOpExecutor* HMS_HiAISingleOpExecutor_CreateConvolution(HiAI_SingleOpExecutorConvolutionParam param);</p> </td> <td class="cellrowborder" valign="top" width="50%"><p>创建卷积类算子对应的HiAI_SingleOpExecutor对象。</p> </td> </tr> <tr><td class="cellrowborder" valign="top" width="50%"><p>size_t HMS_HiAISingleOpExecutor_GetWorkspaceSize (const HiAI_SingleOpExecutor *executor);</p> </td> <td class="cellrowborder" valign="top" width="50%"><p>查询HiAI_SingleOpExecutor所需的ION内存工作空间的字节大小。</p> </td> </tr> <tr><td class="cellrowborder" valign="top" width="50%"><p>OH_NN_ReturnCode HMS_HiAISingleOpExecutor_Init (HiAI_SingleOpExecutor *executor, void *workspace, size_t workspaceSize);</p> </td> <td class="cellrowborder" valign="top" width="50%"><p>加载HiAI_SingleOpExecutor。</p> </td> </tr> <tr><td class="cellrowborder" valign="top" width="50%"><p>OH_NN_ReturnCode HMS_HiAISingleOpExecutor_Execute (HiAI_SingleOpExecutor *executor, HiAI_SingleOpTensor *input[], int32_t inputNum, HiAI_SingleOpTensor *output[], int32_t outputNum);</p> </td> <td class="cellrowborder" valign="top" width="50%"><p>执行同步运算推理。</p> </td> </tr> <tr><td class="cellrowborder" valign="top" width="50%"><p>OH_NN_ReturnCode HMS_HiAISingleOpExecutor_Destroy (HiAI_SingleOpExecutor **executor);</p> </td> <td class="cellrowborder" valign="top" width="50%"><p>销毁HiAI_SingleOpExecutor对象，释放执行器占用的内存。</p> </td> </tr>  </tbody></table></div> </div> </div> <div class="tiledSection"><h2 id="section1373122216206">开发步骤<i class="anchor-icon anchor-icon-link" anchorid="section1373122216206" tips="复制节点链接"></i></h2><p>以下开发步骤以卷积单算子为例。</p> <ol><li><span>创建单算子执行器。</span><p></p><ol><li>调用<a href="https://developer.huawei.com/consumer/cn/doc/harmonyos-references/cannkit#hms_hiaisingleopoptions_create" target="_blank">HMS_HiAISingleOpOptions_Create</a>，创建单算子配置对象。</li><li>调用<a href="https://developer.huawei.com/consumer/cn/doc/harmonyos-references/cannkit#hms_hiaisingleopdescriptor_createconvolution" target="_blank">HMS_HiAISingleOpDescriptor_CreateConvolution</a>，创建卷积类算子描述符对象。</li><li>调用<a href="https://developer.huawei.com/consumer/cn/doc/harmonyos-references/cannkit#hms_hiaisingleoptensor_createfromconst" target="_blank">HMS_HiAISingleOpTensor_CreateFromConst</a>，分别创建卷积算子的权重、偏置单算子Tensor。</li><li>调用<a href="https://developer.huawei.com/consumer/cn/doc/harmonyos-references/cannkit#hms_hiaisingleoptensordesc_create" target="_blank">HMS_HiAISingleOpTensorDesc_Create</a>，分别创建单算子输入Tensor、输出Tensor的描述对象。</li><li>调用<a href="https://developer.huawei.com/consumer/cn/doc/harmonyos-references/cannkit#hms_hiaisingleopexecutor_createconvolution" target="_blank">HMS_HiAISingleOpExecutor_CreateConvolution</a>，将上述创建好的卷积类算子描述符对象、卷积算子的权重Tensor、卷积算子的偏置Tensor、输入Tensor描述、输出Tensor描述作为输入，创建单算子执行器；<p>如果需要创建卷积算子与激活算子的融合算子执行器，还需要调用<a href="https://developer.huawei.com/consumer/cn/doc/harmonyos-references/cannkit#hms_hiaisingleopdescriptor_createactivation" target="_blank">HMS_HiAISingleOpDescriptor_CreateActivation</a>，创建激活类算子描述符对象，然后调用<a href="https://developer.huawei.com/consumer/cn/doc/harmonyos-references/cannkit#hms_hiaisingleopexecutor_createfusedconvolutionactivation" target="_blank">HMS_HiAISingleOpExecutor_CreateFusedConvolutionActivation</a>创建融合算子执行器。</p> </li></ol><ol start="6"><li>创建成功后，调用<a href="https://developer.huawei.com/consumer/cn/doc/harmonyos-references/cannkit#hms_hiaisingleopdescriptor_destroy" target="_blank">HMS_HiAISingleOpDescriptor_Destroy</a>释放算子描述符对象，调用<a href="https://developer.huawei.com/consumer/cn/doc/harmonyos-references/cannkit#hms_hiaisingleopoptions_destroy" target="_blank">HMS_HiAISingleOpOptions_Destroy</a>释放单算子创建配置对象。</li></ol> <p></p></li><li><span>创建输入/输出Tensor。</span><p></p><ol><li>调用<a href="https://developer.huawei.com/consumer/cn/doc/harmonyos-references/cannkit#hms_hiaisingleoptensor_createfromtensordesc" target="_blank">HMS_HiAISingleOpTensor_CreateFromTensorDesc</a>，分别创建单算子输入Tensor、输出Tensor。</li><li>创建成功后，调用<a href="https://developer.huawei.com/consumer/cn/doc/harmonyos-references/cannkit#hms_hiaisingleoptensordesc_destroy" target="_blank">HMS_HiAISingleOpTensorDesc_Destroy</a>释放Tensor描述符对象。</li><li>调用<a href="https://developer.huawei.com/consumer/cn/doc/harmonyos-references/cannkit#hms_hiaisingleoptensor_getbuffer" target="_blank">HMS_HiAISingleOpTensor_GetBuffer</a>，获取输入/输出Tensor内部的Buffer对象。</li><li>调用<a href="https://developer.huawei.com/consumer/cn/doc/harmonyos-references/cannkit#hms_hiaisingleopbuffer_getdata" target="_blank">HMS_HiAISingleOpBuffer_GetData</a>，获取申请好的输入/输出ION内存地址，可用于该单算子在模型整网推理中的输入写入、输出读取。</li></ol> <p></p></li><li><span>加载单算子执行器。</span><p></p><ol><li>调用<a href="https://developer.huawei.com/consumer/cn/doc/harmonyos-references/cannkit#hms_hiaisingleopexecutor_getworkspacesize" target="_blank">HMS_HiAISingleOpExecutor_GetWorkspaceSize</a>，获取已创建的单算子执行器在执行推理计算时需要的ION内存工作空间大小。</li><li>调用<a href="https://developer.huawei.com/consumer/cn/doc/harmonyos-references/cannkit#hms_hiaisingleopbuffer_create" target="_blank">HMS_HiAISingleOpBuffer_Create</a>，根据单算子执行器所需的ION内存工作空间大小创建足够的工作空间。</li><li>调用<a href="https://developer.huawei.com/consumer/cn/doc/harmonyos-references/cannkit#hms_hiaisingleopbuffer_getdata" target="_blank">HMS_HiAISingleOpBuffer_GetData</a>，获取申请好的ION内存工作空间的地址。</li><li>调用<a href="https://developer.huawei.com/consumer/cn/doc/harmonyos-references/cannkit#hms_hiaisingleopexecutor_init" target="_blank">HMS_HiAISingleOpExecutor_Init</a>，使用工作空间内存地址、工作空间大小，加载创建好的单算子执行器。</li></ol> <p></p></li><li><span>执行推理运算。</span><p></p><p>调用<a href="https://developer.huawei.com/consumer/cn/doc/harmonyos-references/cannkit#hms_hiaisingleopexecutor_execute" target="_blank">HMS_HiAISingleOpExecutor_Execute</a>，执行同步运算推理。</p> <p></p></li><li><span>卸载单算子执行器，释放资源。</span><p></p><ul><li>调用<a href="https://developer.huawei.com/consumer/cn/doc/harmonyos-references/cannkit#hms_hiaisingleoptensor_destroy" target="_blank">HMS_HiAISingleOpTensor_Destroy</a>，释放输入、输出Tensor对象</li><li>调用<a href="https://developer.huawei.com/consumer/cn/doc/harmonyos-references/cannkit#hms_hiaisingleopbuffer_destroy" target="_blank">HMS_HiAISingleOpBuffer_Destroy</a>，释放工作空间。</li><li>调用<a href="https://developer.huawei.com/consumer/cn/doc/harmonyos-references/cannkit#hms_hiaisingleopexecutor_destroy" target="_blank">HMS_HiAISingleOpExecutor_Destroy</a>，释放执行器对象。</li></ul> <p></p></li></ol> </div> <div class="tiledSection"><h2 id="section18135413012">示例说明<i class="anchor-icon anchor-icon-link" anchorid="section18135413012" tips="复制节点链接"></i></h2><p>假定现在有一个深度卷积算子，输入维度为1x8x224x224，输入NCHW格式排布的float32类型数据，准备好NCHW排布的权重与偏置数据，调用单算子接口推理运算获得NCHW格式float32类型的输出可以参考如下示例代码：</p> <div _ngcontent-cov-c106="" class="highlight-div"><div _ngcontent-cov-c106="" class="highlight-div-header"><div _ngcontent-cov-c106="" class="highlight-div-header-left"><div _ngcontent-cov-c106="" class="handle-button expand-button"><div _ngcontent-cov-c106="" class="handle-hover-tips">收起</div></div></div><div _ngcontent-cov-c106="" class="highlight-div-header-right"><div _ngcontent-cov-c106="" class="handle-button ai-button"></div><div _ngcontent-cov-c106="" class="handle-button line-button"><div _ngcontent-cov-c106="" class="handle-hover-tips">自动换行</div></div><div _ngcontent-cov-c106="" class="handle-button theme-button"><div _ngcontent-cov-c106="" class="handle-hover-tips">深色代码主题</div></div><div _ngcontent-cov-c106="" class="handle-button copy-button"><div _ngcontent-cov-c106="" class="handle-hover-tips">复制</div></div></div></div><div _ngcontent-cov-c106="" class="highlight-scroll-div"><pre class="cpp prettyprint linenums hljs language-cpp" hw-language="cpp" data-highlighted="yes"><ol class="linenums"><li><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">"CANNKit/hiai_single_op.h"</span></span></li><li><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;cstdio&gt;</span></span></li><li><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;cstdlib&gt;</span></span></li><li><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;cstring&gt;</span></span></li><li><span class="hljs-comment">// 示例算子参数</span></li><li><span class="hljs-comment">// 单算子卷积模式</span></li><li>HiAI_SingleOpConvMode convMode = HIAI_SINGLEOP_CONV_MODE_DEPTHWISE;</li><li><span class="hljs-type">int64_t</span> strides[<span class="hljs-number">2</span>] = {<span class="hljs-number">1</span>, <span class="hljs-number">1</span>};</li><li><span class="hljs-type">int64_t</span> dilations[<span class="hljs-number">2</span>] = {<span class="hljs-number">1</span>, <span class="hljs-number">1</span>};</li><li><span class="hljs-type">int64_t</span> pads[<span class="hljs-number">4</span>] = {<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>};</li><li><span class="hljs-type">int64_t</span> groups = <span class="hljs-number">1</span>;</li><li><span class="hljs-comment">// 单算子填充模式</span></li><li>HiAI_SingleOpPadMode padMode = HIAI_SINGLEOP_PAD_MODE_SAME;</li><li><span class="hljs-type">int64_t</span> filterDims[<span class="hljs-number">4</span>] = {<span class="hljs-number">8</span>, <span class="hljs-number">1</span>, <span class="hljs-number">3</span>, <span class="hljs-number">3</span>};</li><li><span class="hljs-type">size_t</span> filterDataSize = <span class="hljs-number">8</span> * <span class="hljs-number">1</span> * <span class="hljs-number">3</span> * <span class="hljs-number">3</span> * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>);</li><li><span class="hljs-type">void</span>* filterData = <span class="hljs-built_in">malloc</span>(filterDataSize);</li><li><span class="hljs-type">int64_t</span> biasDims[<span class="hljs-number">1</span>] = {<span class="hljs-number">8</span>};</li><li><span class="hljs-type">size_t</span> biasDataSize = <span class="hljs-number">8</span> * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>);</li><li><span class="hljs-type">void</span>* biasData = <span class="hljs-built_in">malloc</span>(biasDataSize);</li><li><span class="hljs-type">int64_t</span> inputDims[<span class="hljs-number">4</span>] = {<span class="hljs-number">1</span>, <span class="hljs-number">8</span>, <span class="hljs-number">224</span>, <span class="hljs-number">224</span>};</li><li>HiAI_SingleOpDataType inputDataType = HIAI_SINGLEOP_DT_FLOAT;</li><li><span class="hljs-comment">// 单算子张量排布格式</span></li><li>HiAI_SingleOpFormat inputFormat = HIAI_SINGLEOP_FORMAT_NCHW;</li><li><span class="hljs-type">bool</span> inputIsVirtual = <span class="hljs-literal">false</span>;</li><li><span class="hljs-comment">// 若不指定算子输出数据类型和排布格式，请设置数据类型为HIAI_SINGLEOP_DT_UNDEFINED，排布格式为HIAI_SINGLEOP_FORMAT_RESERVED</span></li><li><span class="hljs-comment">// 在单算子创建完成后，调用HMS_HiAISingleOpExecutor_UpdateOutputTensorDesc，将输出Tensor描述更新为硬件适配最优的数据类型和排布格式</span></li><li><span class="hljs-type">int64_t</span> outputDims[<span class="hljs-number">4</span>] = {<span class="hljs-number">1</span>, <span class="hljs-number">8</span>, <span class="hljs-number">224</span>, <span class="hljs-number">224</span>};</li><li>HiAI_SingleOpDataType outputDataType = HIAI_SINGLEOP_DT_FLOAT;</li><li>HiAI_SingleOpFormat outputFormat = HIAI_SINGLEOP_FORMAT_NCHW;</li><li><span class="hljs-type">bool</span> outputIsVirtual = <span class="hljs-literal">false</span>;</li><li>
</li><li><span class="hljs-comment">// 创建单算子执行器</span></li><li>HiAI_SingleOpOptions* options = <span class="hljs-built_in">HMS_HiAISingleOpOptions_Create</span>();</li><li>HiAISingleOpDescriptor_ConvolutionParam convOpDescCreateParam = {convMode, {<span class="hljs-number">0</span>}, {<span class="hljs-number">0</span>}, {<span class="hljs-number">0</span>}, groups, padMode};</li><li><span class="hljs-built_in">memcpy</span>(convOpDescCreateParam.strides, strides, <span class="hljs-number">2</span> * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">int64_t</span>));</li><li><span class="hljs-built_in">memcpy</span>(convOpDescCreateParam.dilations, dilations, <span class="hljs-number">2</span> * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">int64_t</span>));</li><li><span class="hljs-built_in">memcpy</span>(convOpDescCreateParam.pads, pads, <span class="hljs-number">4</span> * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">int64_t</span>));</li><li><span class="hljs-comment">// 创建卷积类的描述符对象</span></li><li>HiAI_SingleOpDescriptor* convOpDesc = <span class="hljs-built_in">HMS_HiAISingleOpDescriptor_CreateConvolution</span>(convOpDescCreateParam);</li><li><span class="hljs-comment">// 创建一个单算子tensor描述对象，根据维度、数据类型和格式</span></li><li>HiAI_SingleOpTensorDesc* filterDesc = <span class="hljs-built_in">HMS_HiAISingleOpTensorDesc_Create</span>(filterDims, <span class="hljs-number">4</span>, HIAI_SINGLEOP_DT_FLOAT, HIAI_SINGLEOP_FORMAT_NCHW, <span class="hljs-literal">false</span>);</li><li><span class="hljs-comment">// 创建一个单算子tensor对象</span></li><li>HiAI_SingleOpTensor* filter = <span class="hljs-built_in">HMS_HiAISingleOpTensor_CreateFromConst</span>(filterDesc, filterData, filterDataSize);</li><li>HiAI_SingleOpTensorDesc* biasDesc = <span class="hljs-built_in">HMS_HiAISingleOpTensorDesc_Create</span>(biasDims, <span class="hljs-number">1</span>, HIAI_SINGLEOP_DT_FLOAT, HIAI_SINGLEOP_FORMAT_NCHW, <span class="hljs-literal">false</span>);</li><li>HiAI_SingleOpTensor* bias = <span class="hljs-built_in">HMS_HiAISingleOpTensor_CreateFromConst</span>(biasDesc, biasData, biasDataSize);</li><li>HiAI_SingleOpTensorDesc* inputDesc = <span class="hljs-built_in">HMS_HiAISingleOpTensorDesc_Create</span>(inputDims, <span class="hljs-number">4</span>, inputDataType, inputFormat, inputIsVirtual);</li><li>HiAI_SingleOpTensorDesc* outputDesc = <span class="hljs-built_in">HMS_HiAISingleOpTensorDesc_Create</span>(outputDims, <span class="hljs-number">4</span>, outputDataType, outputFormat, outputIsVirtual);</li><li><span class="hljs-comment">// 构造单算子卷子executor参数</span></li><li>HiAI_SingleOpExecutorConvolutionParam executorCreateParam = {options, convOpDesc, inputDesc, outputDesc, filter, bias};</li><li><span class="hljs-comment">// 创建卷积单算子executor</span></li><li>HiAI_SingleOpExecutor* executor = <span class="hljs-built_in">HMS_HiAISingleOpExecutor_CreateConvolution</span>(executorCreateParam);</li><li><span class="hljs-keyword">if</span> (executor == <span class="hljs-literal">nullptr</span>) {</li><li>    <span class="hljs-built_in">printf</span>(<span class="hljs-string">"HMS_HiAISingleOp executor create failed. \n"</span>);</li><li>}</li><li><span class="hljs-comment">// 对不需要的资源建议即时销毁</span></li><li><span class="hljs-built_in">HMS_HiAISingleOpTensorDesc_Destroy</span>(&amp;filterDesc);</li><li><span class="hljs-built_in">HMS_HiAISingleOpTensorDesc_Destroy</span>(&amp;biasDesc);</li><li><span class="hljs-built_in">HMS_HiAISingleOpOptions_Destroy</span>(&amp;options);</li><li><span class="hljs-built_in">HMS_HiAISingleOpDescriptor_Destroy</span>(&amp;convOpDesc);</li><li>OH_NN_ReturnCode ret = <span class="hljs-built_in">HMS_HiAISingleOpTensor_Destroy</span>(&amp;filter);</li><li><span class="hljs-keyword">if</span> (ret != OH_NN_SUCCESS) {</li><li>    <span class="hljs-built_in">printf</span>(<span class="hljs-string">"HMS_HiAISingleOp filter destroy failed.\n"</span>);</li><li>}</li><li>ret = <span class="hljs-built_in">HMS_HiAISingleOpTensor_Destroy</span>(&amp;bias);</li><li><span class="hljs-keyword">if</span> (ret != OH_NN_SUCCESS) {</li><li>    <span class="hljs-built_in">printf</span>(<span class="hljs-string">"HMS_HiAISingleOp bias destroy failed.\n"</span>);</li><li>}</li><li>
</li><li><span class="hljs-comment">// 创建输入/输出Tensor</span></li><li>HiAI_SingleOpTensor* input = <span class="hljs-built_in">HMS_HiAISingleOpTensor_CreateFromTensorDesc</span>(inputDesc);</li><li><span class="hljs-built_in">HMS_HiAISingleOpTensorDesc_Destroy</span>(&amp;inputDesc);</li><li>HiAI_SingleOpTensor* output = <span class="hljs-built_in">HMS_HiAISingleOpTensor_CreateFromTensorDesc</span>(outputDesc);</li><li><span class="hljs-built_in">HMS_HiAISingleOpTensorDesc_Destroy</span>(&amp;outputDesc);</li><li><span class="hljs-comment">// 单算子输入Tensor和输出Tensor的内存必须为ION内存以节省拷贝开销</span></li><li><span class="hljs-comment">// 创建输入Tensor成功后，可以使用以下方式获取输入Tensor内的ION内存地址进行输入数据填装</span></li><li><span class="hljs-comment">// 输出Tensor内的ION内存地址也可以用以下方式获取，在推理计算成功后用于输出数据读取</span></li><li>HiAI_SingleOpBuffer* inputBuffer = <span class="hljs-built_in">HMS_HiAISingleOpTensor_GetBuffer</span>(input);</li><li><span class="hljs-type">void</span>* inputData = <span class="hljs-built_in">HMS_HiAISingleOpBuffer_GetData</span>(inputBuffer);</li><li><span class="hljs-type">size_t</span> inputDataSize = <span class="hljs-built_in">HMS_HiAISingleOpBuffer_GetSize</span>(inputBuffer);</li><li><span class="hljs-built_in">memset</span>(inputData, <span class="hljs-number">0</span>, inputDataSize);</li><li>
</li><li><span class="hljs-comment">// 查询单算子执行器所需的ION内存工作空间的字节大小</span></li><li><span class="hljs-type">size_t</span> workspaceSize = <span class="hljs-built_in">HMS_HiAISingleOpExecutor_GetWorkspaceSize</span>(executor);</li><li><span class="hljs-comment">// 若存在多个单算子执行器，各个执行器的工作空间内存可以复用，只需要申请所需的最大工作空间即可</span></li><li>HiAI_SingleOpBuffer* workspaceBuffer = <span class="hljs-built_in">HMS_HiAISingleOpBuffer_Create</span>(workspaceSize);</li><li><span class="hljs-type">void</span>* workspace = <span class="hljs-built_in">HMS_HiAISingleOpBuffer_GetData</span>(workspaceBuffer);</li><li>ret = <span class="hljs-built_in">HMS_HiAISingleOpExecutor_Init</span>(executor, workspace, workspaceSize);</li><li><span class="hljs-keyword">if</span> (ret != OH_NN_SUCCESS) {</li><li>    <span class="hljs-built_in">printf</span>(<span class="hljs-string">"HMS_HiAISingleOp executor init failed.\n"</span>);</li><li>}</li><li>
</li><li><span class="hljs-comment">// 执行推理运算</span></li><li>HiAI_SingleOpTensor* inputs[] = {input};</li><li>HiAI_SingleOpTensor* outputs[] = {output};</li><li>ret = <span class="hljs-built_in">HMS_HiAISingleOpExecutor_Execute</span>(executor, inputs, <span class="hljs-number">1</span>, outputs, <span class="hljs-number">1</span>);</li><li><span class="hljs-keyword">if</span> (ret != OH_NN_SUCCESS) {</li><li>    <span class="hljs-built_in">printf</span>(<span class="hljs-string">"HMS_HiAISingleOp executor execute failed.\n"</span>);</li><li>}</li><li>
</li><li><span class="hljs-comment">// 卸载单算子执行器，释放资源</span></li><li>ret = <span class="hljs-built_in">HMS_HiAISingleOpTensor_Destroy</span>(&amp;input);</li><li><span class="hljs-keyword">if</span> (ret != OH_NN_SUCCESS) {</li><li>    <span class="hljs-built_in">printf</span>(<span class="hljs-string">"HMS_HiAISingleOp input destroy failed.\n"</span>);</li><li>}</li><li>ret = <span class="hljs-built_in">HMS_HiAISingleOpTensor_Destroy</span>(&amp;output);</li><li><span class="hljs-keyword">if</span> (ret != OH_NN_SUCCESS) {</li><li>    <span class="hljs-built_in">printf</span>(<span class="hljs-string">"HMS_HiAISingleOp output destroy failed.\n"</span>);</li><li>}</li><li>ret = <span class="hljs-built_in">HMS_HiAISingleOpBuffer_Destroy</span>(&amp;workspaceBuffer);</li><li><span class="hljs-keyword">if</span> (ret != OH_NN_SUCCESS) {</li><li>    <span class="hljs-built_in">printf</span>(<span class="hljs-string">"HMS_HiAISingleOp workspaceBuffer destroy failed.\n"</span>);</li><li>}</li><li>ret = <span class="hljs-built_in">HMS_HiAISingleOpExecutor_Destroy</span>(&amp;executor);</li><li><span class="hljs-keyword">if</span> (ret != OH_NN_SUCCESS) {</li><li>    <span class="hljs-built_in">printf</span>(<span class="hljs-string">"HMS_HiAISingleOp executor destroy failed.\n"</span>);</li><li>}</li><li><span class="hljs-built_in">free</span>(filterData);</li><li><span class="hljs-built_in">free</span>(biasData);</li></ol></pre></div></div> </div> </div> <div></div></div>