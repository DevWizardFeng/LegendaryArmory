<h1 _ngcontent-hhf-c119="" class="doc-title ng-star-inserted" title="模型推理"> 模型推理 </h1>

<div _ngcontent-hhf-c106="" auitextselectionexpansion="" class="markdown-body ng-star-inserted" style="position: relative;"> <div><div class="tiledSection"><h2 id="section16522171851016">基本概念<i class="anchor-icon anchor-icon-link" anchorid="section16522171851016" tips="复制节点链接"></i></h2><p>该场景是基本模型的使用场景，主要包含模型的编译和推理，其他场景是基础场景的一个扩展和功能增强。</p> </div> <div class="tiledSection"><h2 id="section1818915573916">业务流程<i class="anchor-icon anchor-icon-link" anchorid="section1818915573916" tips="复制节点链接"></i></h2><p>模型推理的主要开发流程如下图所示：</p> <p><span><img height="524.6850000000001" originheight="3494" originwidth="3481" src="https://alliance-communityfile-drcn.dbankcdn.com/FileServer/getFile/cmtyPub/011/111/111/0000000000011111111.20251211114230.83657981376541076151592221669047:50001231000000:2800:2084BAA68BC6C94F569219359E995060BD64AA584FDEEB23A0CEFEBE93896F13.png" title="点击放大" width="523.6875"></span></p> </div> <div class="tiledSection"><h2 id="section5906121818412">接口说明<i class="anchor-icon anchor-icon-link" anchorid="section5906121818412" tips="复制节点链接"></i></h2><p>以下接口为主要流程接口，如要使用更丰富的编译、加载和执行时的配置，请参见<a href="https://developer.huawei.com/consumer/cn/doc/harmonyos-references/cannkit" target="_blank">API参考</a>。</p>  <div class="tablenoborder"><div class="tbBox"><table class="layoutFixed idpTab"><caption><b>表1 </b>CANN Kit模型推理相关接口功能介绍</caption><thead><tr><th align="left" class="cellrowborder" id="mcps1.3.3.3.2.3.1.1" valign="top" width="57.620000000000005%"><p>接口名</p> </th> <th align="left" class="cellrowborder" id="mcps1.3.3.3.2.3.1.2" valign="top" width="42.38%"><p>描述</p> </th> </tr> </thead> <tbody><tr><td class="cellrowborder" valign="top" width="57.620000000000005%"><p>OH_NNCompilation* OH_NNCompilation_ConstructWithOfflineModelBuffer(const void *modelBuffer, size_t modelSize);</p> </td> <td class="cellrowborder" valign="top" width="42.38%"><p>根据模型buffer创建模型编译实例。</p> </td> </tr> <tr><td class="cellrowborder" valign="top" width="57.620000000000005%"><p>OH_NN_ReturnCode OH_NNCompilation_SetDevice(OH_NNCompilation *compilation, size_t deviceID);</p> </td> <td class="cellrowborder" valign="top" width="42.38%"><p>设置模型编译和执行的目标设备。</p> </td> </tr> <tr><td class="cellrowborder" valign="top" width="57.620000000000005%"><p>OH_NN_ReturnCode OH_NNCompilation_Build(OH_NNCompilation *compilation);</p> </td> <td class="cellrowborder" valign="top" width="42.38%"><p>执行模型编译，生成编译后的模型保存在compilation中。</p> </td> </tr> <tr><td class="cellrowborder" valign="top" width="57.620000000000005%"><p>OH_NNExecutor* OH_NNExecutor_Construct(OH_NNCompilation *compilation);</p> </td> <td class="cellrowborder" valign="top" width="42.38%"><p>根据编译后的模型，创建模型推理的执行器。</p> </td> </tr> <tr><td class="cellrowborder" valign="top" width="57.620000000000005%"><p>NN_Tensor* OH_NNTensor_Create(size_t deviceID, NN_TensorDesc* tensorDesc);</p> </td> <td class="cellrowborder" valign="top" width="42.38%"><p>构造输入输出Tensor。</p> </td> </tr> <tr><td class="cellrowborder" valign="top" width="57.620000000000005%"><p>OH_NN_ReturnCode OH_NNExecutor_RunSync(OH_NNExecutor *executor, NN_Tensor *inputTensor[], size_t inputCount, NN_Tensor *outputTensor[], size_t outputCount);</p> </td> <td class="cellrowborder" valign="top" width="42.38%"><p>执行模型的同步推理。</p> </td> </tr> <tr><td class="cellrowborder" valign="top" width="57.620000000000005%"><p>void OH_NNCompilation_Destroy(OH_NNCompilation **compilation);</p> </td> <td class="cellrowborder" valign="top" width="42.38%"><p>销毁模型编译实例。</p> </td> </tr> <tr><td class="cellrowborder" valign="top" width="57.620000000000005%"><p>OH_NN_ReturnCode OH_NNTensor_Destroy(NN_Tensor** tensor);</p> </td> <td class="cellrowborder" valign="top" width="42.38%"><p>销毁输入输出Tensor。</p> </td> </tr> <tr><td class="cellrowborder" valign="top" width="57.620000000000005%"><p>void OH_NNExecutor_Destroy(OH_NNExecutor **executor);</p> </td> <td class="cellrowborder" valign="top" width="42.38%"><p>销毁模型推理的执行器。</p> </td> </tr>  </tbody></table></div> </div> </div> <div class="tiledSection"><h2 id="section9187179113620">开发步骤<i class="anchor-icon anchor-icon-link" anchorid="section9187179113620" tips="复制节点链接"></i></h2><p>以下为模型推理的主要开发步骤，具体实现请参见<a href="https://gitcode.com/HarmonyOS_Samples/cannkit-samplecode-clientdemo-cpp" target="_blank">SampleCode</a>。</p> <ol><li><span>准备模型和开发环境。</span><p></p><ul><li>准备om模型，可以通过tools_omg工具生成或从<a href="https://developer.huawei.com/consumer/cn/doc/harmonyos-guides/cannkit-model-zoo">Model Zoo</a>获取。</li><li>下载并配置<a href="https://developer.huawei.com/consumer/cn/deveco-studio/" target="_blank">DevEco Studio</a> 环境，确保可以正常开发和调试HarmonyOS应用。</li></ul> <p></p></li></ol><ol start="2"><li><span><a href="https://developer.huawei.com/consumer/cn/doc/harmonyos-guides/cannkit-creating-a-project">创建DevEco Studio项目</a>。</span></li></ol><ol start="3"><li id="li810206624"><span>创建模型编译实例。</span><p></p><p>调用<a href="https://developer.huawei.com/consumer/cn/doc/harmonyos-references/capi-neural-network-core-h#oh_nncompilation_constructwithofflinemodelbuffer" target="_blank">OH_NNCompilation_ConstructWithOfflineModelBuffer</a>读取模型buffer，创建模型编译实例。或者通过调用<a href="https://developer.huawei.com/consumer/cn/doc/harmonyos-references/capi-neural-network-core-h#oh_nncompilation_constructwithofflinemodelfile" target="_blank">OH_NNCompilation_ConstructWithOfflineModelFile</a>直接读取模型文件，创建模型编译实例。</p> <p></p></li><li><span>选择目标device。</span><p></p><p>调用<a href="https://developer.huawei.com/consumer/cn/doc/harmonyos-references/capi-neural-network-core-h#oh_nndevice_getalldevicesid" target="_blank">OH_NNDevice_GetAllDevicesID</a>，获取所有的设备ID，查找name为"HIAI_F"字段的设备ID，记录并通过<a href="https://developer.huawei.com/consumer/cn/doc/harmonyos-references/capi-neural-network-core-h#oh_nncompilation_setdevice" target="_blank">OH_NNCompilation_SetDevice</a>设置到<a href="/consumer/cn/doc/harmonyos-guides/cannkit-model-inference#li810206624">步骤3</a>创建的编译实例中。</p> <p></p></li></ol><ol start="5"><li><span>执行模型编译。</span><p></p><p>调用<a href="https://developer.huawei.com/consumer/cn/doc/harmonyos-references/capi-neural-network-core-h#oh_nncompilation_build" target="_blank">OH_NNCompilation_Build</a>，传入<a href="/consumer/cn/doc/harmonyos-guides/cannkit-model-inference#li810206624">步骤3</a>创建的模型编译实例，即可执行模型编译，编译后的模型数据仍然保存在模型编译实例中。</p> <p></p></li></ol><ol start="6"><li><span>创建模型执行器。</span><p></p><p>调用<a href="https://developer.huawei.com/consumer/cn/doc/harmonyos-references/capi-neural-network-core-h#oh_nnexecutor_construct" target="_blank">OH_NNExecutor_Construct</a>，创建编译后模型对应的执行器实例。执行器创建完成后即可调用<a href="https://developer.huawei.com/consumer/cn/doc/harmonyos-references/capi-neural-network-core-h#oh_nncompilation_destroy" target="_blank">OH_NNCompilation_Destroy</a>销毁模型编译实例。</p> <p></p></li></ol><ol start="7"><li id="li10555614927"><span>构造输入输出Tensor。</span><p></p><p>调用<a href="https://developer.huawei.com/consumer/cn/doc/harmonyos-references/capi-neural-network-core-h#oh_nnexecutor_getinputcount" target="_blank">OH_NNExecutor_GetInputCount</a>，查询输入的个数，通过<a href="https://developer.huawei.com/consumer/cn/doc/harmonyos-references/capi-neural-network-core-h#oh_nnexecutor_createinputtensordesc" target="_blank">OH_NNExecutor_CreateInputTensorDesc</a>获取到对应索引的TensorDesc，根据该TensorDesc通过<a href="https://developer.huawei.com/consumer/cn/doc/harmonyos-references/capi-neural-network-core-h#oh_nntensor_create" target="_blank">OH_NNTensor_Create</a>创建Tensor，即可向Tensor中写入实际数据。输出Tensor的构造与输入Tensor的构造过程一致。</p> <p></p></li></ol><ol start="8"><li id="li510118171220"><span>执行模型推理。</span><p></p><p>调用<a href="https://developer.huawei.com/consumer/cn/doc/harmonyos-references/capi-neural-network-core-h#oh_nnexecutor_runsync" target="_blank">OH_NNExecutor_RunSync</a>，执行模型的同步推理功能，模型的输出数据保存在outputTensors中。开发者可根据需要对输出数据做相应的处理以得到期望的内容。</p> <p></p></li></ol><ol start="9"><li id="li172172195213"><span>销毁实例。</span><p></p><ul><li>调用<a href="https://developer.huawei.com/consumer/cn/doc/harmonyos-references/capi-neural-network-core-h#oh_nnexecutor_destroy" target="_blank">OH_NNExecutor_Destroy</a>，销毁创建的模型执行器实例。</li><li>调用<a href="https://developer.huawei.com/consumer/cn/doc/harmonyos-references/capi-neural-network-core-h#oh_nntensor_destroy" target="_blank">OH_NNTensor_Destroy</a>，销毁创建的输入输出Tensor。</li></ul> <p></p></li></ol> </div> </div> <div></div></div>