<h1 _ngcontent-qmd-c119="" class="doc-title ng-star-inserted" title="编程范式"> 编程范式 </h1>

<div _ngcontent-qmd-c106="" auitextselectionexpansion="" class="markdown-body ng-star-inserted" style="position: relative;"> <div><p>编程范式描述了算子实现的固定流程，基于编程范式进行编程，可以快速搭建算子实现的代码框架。</p> <p>根据<a href="https://developer.huawei.com/consumer/cn/doc/harmonyos-guides/cannkit-hardware-architecture-abstraction">硬件架构抽象</a>可以了解到，AI Core内部的执行单元异步并行地执行接收到的指令。如下图所示，从输入数据到输出数据需要经过3个阶段任务的处理（T1、T2、T3），多个执行单元并行处理，每个执行单元只会专注于一个任务的处理，会处理所有的数据分片。可以看出，流水线并行和工业生产中的流水线是类似的，每一个执行单元都可以看成是流水线上的节点，通过流水线并行的方式来提高计算效率：执行单元1完成对某个数据分片的处理后，将其加入到通信队列，执行单元2空闲时就会从队列中取出数据继续处理；可以类比为生产流水线中的工人只完成某一项固定工序，完成后就交由下一项工序负责人继续处理。</p> <p><span><img height="115.71000000000001" originheight="174" originwidth="798" src="https://alliance-communityfile-drcn.dbankcdn.com/FileServer/getFile/cmtyPub/011/111/111/0000000000011111111.20251211114306.97786464240154305463391369732239:50001231000000:2800:696925E7DF59332E51586EFA1158F3E21063846F6E0F1CEA19790E77E3E0715C.png" title="点击放大" width="526.6800000000001"></span></p> <p>AscendC编程范式就是这样一种流水线式的编程范式，把算子核内的处理程序，分成多个<strong>流水任务</strong>，通过队列(Queue)完成<strong>任务间通信和同步</strong>，并通过统一的<strong>资源管理</strong>模块(Pipe)来统一管理内存、事件等资源。</p> <div class="tiledSection"><h2 id="section715mcpsimp">Vector编程范式<i class="anchor-icon anchor-icon-link" anchorid="section715mcpsimp" tips="复制节点链接"></i></h2><p class="msonormal"><span><img height="123.69000000000001" originheight="182" originwidth="787" src="https://alliance-communityfile-drcn.dbankcdn.com/FileServer/getFile/cmtyPub/011/111/111/0000000000011111111.20251211114306.95511629795501842567861931909106:50001231000000:2800:EAB96EC37ABAEDBCE18B879E75A146A1B6BDEFE4FF38B95788E053EA489EA48D.png" title="点击放大" width="526.6800000000001"></span></p> <p>如上图所示，Vector编程范式把算子的实现流程分为3个基本任务：CopyIn，Compute，CopyOut。</p> <ul><li><strong>CopyIn</strong>负责搬入操作：将输入数据从Global Memory搬运到Local Memory（VECIN用于表达矢量计算搬入数据的存放位置），完成搬运后执行入队列操作。</li><li><strong>Compute</strong>负责矢量指令计算操作：完成队列出队后，从Local Memory获取数据并计算，计算完成后执行入队操作。</li><li><strong>CopyOut</strong>负责搬出操作：完成队列出队后，将计算结果从Local Memory（VECOUT用于表达矢量计算搬出数据的存放位置）搬运到GM。</li></ul> <p>上文中提到的VECIN/VECOUT是TPosition的概念。AscendC管理不同层级的物理内存时，用一种抽象的逻辑位置(TPosition)来表达各级别的存储，代替了片上物理存储的概念，达到隐藏硬件架构的目的。除了VECIN/VECOUT，矢量编程中还会使用到VECCALC，一般在定义临时变量时使用此位置。这些TPosition与物理内存的映射关系如下表。</p>  <div class="tablenoborder"><div class="tbBox"><table class="layoutFixed idpTab"><caption><b>表1 </b>TPosition与物理内存映射关系</caption><thead><tr><th align="left" class="cellrowborder" id="mcps1.3.5.6.2.3.1.1" valign="top" width="50%"><p>TPosition</p> </th> <th align="left" class="cellrowborder" id="mcps1.3.5.6.2.3.1.2" valign="top" width="50%"><p>物理内存</p> </th> </tr> </thead> <tbody><tr><td class="cellrowborder" valign="top" width="50%"><p>GM</p> </td> <td class="cellrowborder" valign="top" width="50%"><p>Global Memory</p> </td> </tr> <tr><td class="cellrowborder" valign="top" width="50%"><p>VECIN</p> </td> <td class="cellrowborder" valign="top" width="50%"><p>Unified Buffer</p> </td> </tr> <tr><td class="cellrowborder" valign="top" width="50%"><p>VECOUT</p> </td> <td class="cellrowborder" valign="top" width="50%"><p>Unified Buffer</p> </td> </tr> <tr><td class="cellrowborder" valign="top" width="50%"><p>VECCALC</p> </td> <td class="cellrowborder" valign="top" width="50%"><p>Unified Buffer</p> </td> </tr>  </tbody></table></div> </div> <p>从编程的角度来讲，具体流程（如下文的伪代码）和流程图如下。</p> <p class="msonormal"><span><img height="191.52" originheight="362" originwidth="982" src="https://alliance-communityfile-drcn.dbankcdn.com/FileServer/getFile/cmtyPub/011/111/111/0000000000011111111.20251211114306.49939448422341043057739485324062:50001231000000:2800:7F645FA2F8BAD9138B2706D35403BA99113205B70BC91BD0678850B750359D1F.png" title="点击放大" width="526.6800000000001"></span></p> <div _ngcontent-qmd-c106="" class="highlight-div"><div _ngcontent-qmd-c106="" class="highlight-div-header"><div _ngcontent-qmd-c106="" class="highlight-div-header-left"><div _ngcontent-qmd-c106="" class="handle-button expand-button"><div _ngcontent-qmd-c106="" class="handle-hover-tips">收起</div></div></div><div _ngcontent-qmd-c106="" class="highlight-div-header-right"><div _ngcontent-qmd-c106="" class="handle-button ai-button"></div><div _ngcontent-qmd-c106="" class="handle-button line-button"><div _ngcontent-qmd-c106="" class="handle-hover-tips">自动换行</div></div><div _ngcontent-qmd-c106="" class="handle-button theme-button"><div _ngcontent-qmd-c106="" class="handle-hover-tips">深色代码主题</div></div><div _ngcontent-qmd-c106="" class="handle-button copy-button"><div _ngcontent-qmd-c106="" class="handle-hover-tips">复制</div></div></div></div><div _ngcontent-qmd-c106="" class="highlight-scroll-div"><pre class="cpp prettyprint linenums hljs language-cpp" hw-language="cpp" data-highlighted="yes"><ol class="linenums"><li>AscendC::TPipe pipe;                                    <span class="hljs-comment">// 创建全局的资源管理</span></li><li>AscendC::TQue&lt;AscendC::QuePosition::VecIn, <span class="hljs-number">1</span>&gt; queIn;    <span class="hljs-comment">// 创建CopyIn阶段的队列</span></li><li>AscendC::TQue&lt;AscendC::QuePosition::VecOut, <span class="hljs-number">1</span>&gt; queOut;  <span class="hljs-comment">// 创建CopyOut阶段的队列</span></li><li><span class="hljs-comment">// Init 阶段： </span></li><li>pipe.<span class="hljs-built_in">InitBuffer</span>(queIn, <span class="hljs-number">2</span>, <span class="hljs-number">1024</span>);                        <span class="hljs-comment">// 开启double buffer,将待处理的数据一分为二,实现流水并行</span></li><li><span class="hljs-keyword">for</span>-loop { </li><li>    <span class="hljs-comment">// CopyIn 阶段{ </span></li><li>    <span class="hljs-keyword">auto</span> tensor = queIn.<span class="hljs-built_in">AllocTensor</span>&lt;half&gt;();            <span class="hljs-comment">// 从Que上申请资源, 长度1024字节</span></li><li>    AscendC::<span class="hljs-built_in">DataCopy</span>(tensor, gm, len);                 <span class="hljs-comment">// 搬运数据从GM到VECIN</span></li><li>    queIn.<span class="hljs-built_in">EnQue</span>(tensor);  </li><li>    <span class="hljs-comment">// } </span></li><li>    <span class="hljs-comment">// Compute 阶段{ </span></li><li>    <span class="hljs-keyword">auto</span> tensor = queIn.<span class="hljs-built_in">DeQue</span>&lt;half&gt;(); </li><li>    <span class="hljs-keyword">auto</span> tensorOut = queOut.<span class="hljs-built_in">AllocTensor</span>&lt;half&gt;(); </li><li>    AscendC::<span class="hljs-built_in">Abs</span>(tensorOut, tensor, <span class="hljs-number">1024</span>); </li><li>    queIn.<span class="hljs-built_in">FreeTensor</span>(tensor); </li><li>    queOut.<span class="hljs-built_in">EnQue</span>(tensorOut); </li><li>    <span class="hljs-comment">// } </span></li><li>    <span class="hljs-comment">// CopyOut 阶段{ </span></li><li>    <span class="hljs-keyword">auto</span> tensor = queOut.<span class="hljs-built_in">DeQue</span>&lt;half&gt;(); </li><li>    AscendC::<span class="hljs-built_in">DataCopy</span>(gmOut, tensor, <span class="hljs-number">1024</span>); </li><li>    queOut.<span class="hljs-built_in">FreeTensor</span>(tensor); </li><li>    <span class="hljs-comment">// } </span></li><li>}</li></ol></pre></div></div> <p>任务间数据传递使用到的内存、事件等资源统一由管理模块Pipe进行管理。如下所示的内存管理示意图，TPipe通过<a href="https://developer.huawei.com/consumer/cn/doc/harmonyos-guides/cannkit-tpipe-initbuffer">InitBuffer</a>接口对外提供Queue内存初始化功能，开发者可以通过该接口为指定的Queue分配内存。</p> <p>Queue队列内存初始化完成后，需要使用内存时，通过调用<a href="https://developer.huawei.com/consumer/cn/doc/harmonyos-guides/cannkit-tque-alloctensor">AllocTensor</a>来为LocalTensor分配内存，当创建的LocalTensor完成相关计算无需再使用时，再调用<a href="https://developer.huawei.com/consumer/cn/doc/harmonyos-guides/cannkit-tque-freetensor">FreeTensor</a>来回收LocalTensor的内存。</p> <p><span><img height="182.21" originheight="179" originwidth="523" src="https://alliance-communityfile-drcn.dbankcdn.com/FileServer/getFile/cmtyPub/011/111/111/0000000000011111111.20251211114307.56065377042308716083594464798468:50001231000000:2800:0343CE77AD8832C532B8D52632BF7B258FD6F1D3B090B59BC87114849EBCCA56.png" title="点击放大" width="526.6800000000001"></span></p> <p>编程过程中使用到的临时变量内存同样通过Pipe进行管理。临时变量可以使用TBuf数据结构来申请指定TPosition上的存储空间。使用TBuf申请的内存空间只能参与计算，无法执行Queue队列的入队出队操作。具体的接口使用说明请参考<a href="https://developer.huawei.com/consumer/cn/doc/harmonyos-guides/cannkit-tbuf-overview">TBuf</a>。</p> <p>按照上述编程范式进行编程即可实现单核上数据的并行处理。需要处理的数据被切分成n片，每个并行任务（Stage1、2、3）需要依次完成n个数据切片的处理。Stage间的箭头表达数据间的依赖关系，比如Stage1(CopyIn)处理完第一个数据分片之后，Stage2(Compute)才能对该分片进行处理。</p> <p><span><img height="143.64000000000001" originheight="222" originwidth="819" src="https://alliance-communityfile-drcn.dbankcdn.com/FileServer/getFile/cmtyPub/011/111/111/0000000000011111111.20251211114307.13223028927761515581409619015475:50001231000000:2800:D2C4CB2D4B5CAABC4EE5E7280DAA79F5447A9A0A3F1C151CD33CBC5835B6137F.png" title="点击放大" width="526.6800000000001"></span></p> <p>上图中的流水任务运行起来的示意图如下，Progress1、2、3代表处理的数据分片，从运行图中可以看出，对于同一片数据，Stage1、Stage2、Stage3之间的处理具有依赖关系，需要串行处理。不同的数据切片，同一时间点，可以有多个任务在并行处理，由此达到任务并行、提升性能的目的。</p> <p><span><img height="191.52" originheight="266" originwidth="731" src="https://alliance-communityfile-drcn.dbankcdn.com/FileServer/getFile/cmtyPub/011/111/111/0000000000011111111.20251211114307.38969482795803207297173524202523:50001231000000:2800:7DCE69EC51E27982CEE824A5FBA4F087D8911652402F47781236FD4023D7DA99.png" title="点击放大" width="526.6800000000001"></span></p> </div> <div class="tiledSection"><h2 id="section777mcpsimp">Cube编程范式<i class="anchor-icon anchor-icon-link" anchorid="section777mcpsimp" tips="复制节点链接"></i></h2><p>Cube计算的典型数据流图如下所示：</p> <p class="msonormal"><span><img height="228.76000000000002" originheight="365" originwidth="838" src="https://alliance-communityfile-drcn.dbankcdn.com/FileServer/getFile/cmtyPub/011/111/111/0000000000011111111.20251211114307.16782256466955297715114862432323:50001231000000:2800:7B37ECCE0E4B59E52F50233215FB89555901A9CE3601B2370A7DD000546408F6.png" title="点击放大" width="526.6800000000001"></span></p> <p>和矢量编程范式一样，同样也使用逻辑位置(TPosition)来表达数据流，Cube编程范式中主要使用的逻辑位置定义如下。</p> <ul><li>搬入数据的存放位置：A1，用于存放整块A矩阵，可类比CPU多级缓存中的二级缓存。</li><li>搬入数据的存放位置：B1，用于存放整块B矩阵，可类比CPU多级缓存中的二级缓存。</li><li>搬入数据的存放位置：A2，用于存放切分后的小块A矩阵，可类比CPU多级缓存中的一级缓存。</li><li>搬入数据的存放位置：B2，用于存放切分后的小块B矩阵，可类比CPU多级缓存中的一级缓存。</li><li>结果数据的存放位置：CO1，用于存放小块结果C矩阵，可理解为Cube Out。</li><li>结果数据的存放位置：CO2，用于存放整块结果C矩阵，可理解为Cube Out。</li><li>搬入数据的存放位置：VECIN，用于矢量计算，实际业务在数据搬入Vector计算单元时使用此位置。</li><li>搬入数据的存放位置：VECCALC，用于矢量计算，实际业务一般在计算需要临时变量时使用此位置。</li><li>搬出数据的存放位置：VECOUT，用于矢量计算，实际业务在将Vector计算单元结果搬出时使用此位置。</li></ul> <p>上述TPosition与物理内存的映射关系如下。</p>  <div class="tablenoborder"><div class="tbBox"><table class="layoutFixed idpTab"><caption><b>表2 </b>TPosition与物理内存映射关系</caption><thead><tr><th align="left" class="cellrowborder" id="mcps1.3.6.7.2.3.1.1" valign="top" width="27.200000000000003%"><p>TPosition</p> </th> <th align="left" class="cellrowborder" id="mcps1.3.6.7.2.3.1.2" valign="top" width="72.8%"><p>物理内存</p> </th> </tr> </thead> <tbody><tr><td class="cellrowborder" valign="top" width="27.200000000000003%"><p>GM</p> </td> <td class="cellrowborder" valign="top" width="72.8%"><p>Global Memory</p> </td> </tr> <tr><td class="cellrowborder" valign="top" width="27.200000000000003%"><p>VECIN</p> </td> <td class="cellrowborder" valign="top" width="72.8%"><p>Unified Buffer</p> </td> </tr> <tr><td class="cellrowborder" valign="top" width="27.200000000000003%"><p>VECCALC</p> </td> <td class="cellrowborder" valign="top" width="72.8%"><p>Unified Buffer</p> </td> </tr> <tr><td class="cellrowborder" valign="top" width="27.200000000000003%"><p>VECOUT</p> </td> <td class="cellrowborder" valign="top" width="72.8%"><p>Unified Buffer</p> </td> </tr> <tr><td class="cellrowborder" valign="top" width="27.200000000000003%"><p>A1</p> </td> <td class="cellrowborder" valign="top" width="72.8%"><p>L1 Buffer</p> </td> </tr> <tr><td class="cellrowborder" valign="top" width="27.200000000000003%"><p>A2</p> </td> <td class="cellrowborder" valign="top" width="72.8%"><p>L0A Buffer</p> </td> </tr> <tr><td class="cellrowborder" valign="top" width="27.200000000000003%"><p>B1</p> </td> <td class="cellrowborder" valign="top" width="72.8%"><p>L1 Buffer</p> </td> </tr> <tr><td class="cellrowborder" valign="top" width="27.200000000000003%"><p>B2</p> </td> <td class="cellrowborder" valign="top" width="72.8%"><p>L0B Buffer</p> </td> </tr> <tr><td class="cellrowborder" valign="top" width="27.200000000000003%"><p>C1</p> </td> <td class="cellrowborder" valign="top" width="72.8%"><p>Kirin9020系列产品，L1 Buffer。</p> </td> </tr> <tr><td class="cellrowborder" valign="top" width="27.200000000000003%"><p>C2</p> </td> <td class="cellrowborder" valign="top" width="72.8%"><p>Kirin9020系列产品，BT Buffer。</p> </td> </tr> <tr><td class="cellrowborder" valign="top" width="27.200000000000003%"><p>CO1</p> </td> <td class="cellrowborder" valign="top" width="72.8%"><p>L0C Buffer</p> </td> </tr> <tr><td class="cellrowborder" valign="top" width="27.200000000000003%"><p>CO2</p> </td> <td class="cellrowborder" valign="top" width="72.8%"><p>Kirin9020系列产品，Global Memory。</p> </td> </tr>  </tbody></table></div> </div> <p>Cube计算流程同样也可以理解为CopyIn、Compute、CopyOut这几个阶段，因为流程相对复杂，Matmul高阶API提供对此的高阶封装，编程范式如下。</p> <p class="msonormal"><span><img height="228.76000000000002" originheight="365" originwidth="838" src="https://alliance-communityfile-drcn.dbankcdn.com/FileServer/getFile/cmtyPub/011/111/111/0000000000011111111.20251211114307.95414638624417675344796986437797:50001231000000:2800:59230D4802FAEE40CBDE13E40A0FFC76C71F685D04D9E28475762F1BBFBDED5D.png" title="点击放大" width="526.6800000000001"></span></p> <p>图中线条表示数据流向</p> <p></p> <p>具体流程可参考如下示例：</p> <div _ngcontent-qmd-c106="" class="highlight-div"><div _ngcontent-qmd-c106="" class="highlight-div-header"><div _ngcontent-qmd-c106="" class="highlight-div-header-left"><div _ngcontent-qmd-c106="" class="handle-button expand-button"><div _ngcontent-qmd-c106="" class="handle-hover-tips">收起</div></div></div><div _ngcontent-qmd-c106="" class="highlight-div-header-right"><div _ngcontent-qmd-c106="" class="handle-button ai-button"></div><div _ngcontent-qmd-c106="" class="handle-button line-button"><div _ngcontent-qmd-c106="" class="handle-hover-tips">自动换行</div></div><div _ngcontent-qmd-c106="" class="handle-button theme-button"><div _ngcontent-qmd-c106="" class="handle-hover-tips">深色代码主题</div></div><div _ngcontent-qmd-c106="" class="handle-button copy-button"><div _ngcontent-qmd-c106="" class="handle-hover-tips">复制</div></div></div></div><div _ngcontent-qmd-c106="" class="highlight-scroll-div"><pre class="cpp prettyprint linenums hljs language-cpp" hw-language="cpp" data-highlighted="yes"><ol class="linenums"><li><span class="hljs-comment">// 创建Matmul对象 创建对象时需要传入A、B、C、Bias的参数类型信息， 类型信息通过MatmulType来定义，包括：内存逻辑位置、数据格式、数据类型。 </span></li><li><span class="hljs-keyword">typedef</span> MatmulType&lt;TPosition::GM, CubeFormat::ND, half&gt; aType;  </li><li><span class="hljs-keyword">typedef</span> MatmulType&lt;TPosition::GM, CubeFormat::ND, half&gt; bType;  </li><li><span class="hljs-keyword">typedef</span> MatmulType&lt;TPosition::GM, CubeFormat::ND, <span class="hljs-type">float</span>&gt; cType;  </li><li><span class="hljs-keyword">typedef</span> MatmulType&lt;TPosition::GM, CubeFormat::ND, <span class="hljs-type">float</span>&gt; biasType;  </li><li>Matmul&lt;aType, bType, cType, biasType&gt; mm;  </li><li> </li><li><span class="hljs-built_in">REGIST_MATMUL_OBJ</span>(&amp;pipe, <span class="hljs-built_in">GetSysWorkSpacePtr</span>(), mm, &amp;tiling); <span class="hljs-comment">// 初始化 </span></li><li><span class="hljs-comment">// CopyIn阶段：完成从GM到LocalMemory的搬运 </span></li><li>mm.<span class="hljs-built_in">SetTensorA</span>(gm_a);    <span class="hljs-comment">// 设置左矩阵A </span></li><li>mm.<span class="hljs-built_in">SetTensorB</span>(gm_b);    <span class="hljs-comment">// 设置右矩阵B </span></li><li>mm.<span class="hljs-built_in">SetBias</span>(gm_bias);    <span class="hljs-comment">// 设置Bias </span></li><li><span class="hljs-comment">// Compute阶段：完成矩阵乘计算 </span></li><li><span class="hljs-keyword">while</span> (mm.<span class="hljs-built_in">Iterate</span>()) {  </li><li>    <span class="hljs-comment">// CopyOut阶段：完成从LocalMemory到GM的搬运 </span></li><li>    mm.<span class="hljs-built_in">GetTensorC</span>(gm_c);  </li><li>} </li><li><span class="hljs-comment">// 结束矩阵乘操作 </span></li><li>mm.<span class="hljs-built_in">End</span>();</li></ol></pre></div></div> </div> <div class="tiledSection"><h2 id="section878mcpsimp">融合算子编程范式<i class="anchor-icon anchor-icon-link" anchorid="section878mcpsimp" tips="复制节点链接"></i></h2><p>支持Vector与Cube混合计算的算子称之为融合算子。AscendC提供<strong>融合算子的编程范式</strong>，方便开发者基于该范式表达融合算子的数据流，快速实现自己的融合算子。</p> <p><strong>融合算子数据流</strong>指融合算子的输入输出在各存储位置间的流向。以一个典型的Cube和Vector融合算子为例，逻辑位置间的数据流向如下图所示（为了简化描述，没有列出bias）：</p> <ul><li>Cube的输出可以作为Vector的输入：CO2-&gt;VECIN</li><li>Vector的输出可以作为Cube的输入：VECOUT-&gt;A1-&gt;A2、VECOUT-&gt;B1-&gt;B2</li></ul> <p class="msonormal"><span><img height="228.76000000000002" originheight="365" originwidth="838" src="https://alliance-communityfile-drcn.dbankcdn.com/FileServer/getFile/cmtyPub/011/111/111/0000000000011111111.20251211114307.71050919306165652911628285187180:50001231000000:2800:3154A883B8F4E7386CD4C18888FC35B88246001BD5E9C839F958FDEFFF001DB9.png" title="点击放大" width="526.6800000000001"></span></p> <p>基于Matmul高阶API的融合算子编程范式，对上述数据流简化表达如下。</p> <p><span><img height="219.45000000000002" originheight="282" originwidth="662" src="https://alliance-communityfile-drcn.dbankcdn.com/FileServer/getFile/cmtyPub/011/111/111/0000000000011111111.20251211114307.62621370058831192701425405395302:50001231000000:2800:FE128471918B4D026D06B0D30C0D5596EF8C239A6D5F66918A42570BE5B82F1E.png" title="点击放大" width="526.6800000000001"></span></p> <ol><li>初始化一个MatMul对象，将输入数据从Global Memory搬运到Cube核上。</li><li>进行MatMul内部的计算。</li><li>将MatMul的计算结果搬运到Vector核上。</li><li>进行Vector矢量计算。</li><li>将输出结果搬运到Global Memory上。</li></ol> <p>整个过程的示例代码如下（伪代码）：</p> <div _ngcontent-qmd-c106="" class="highlight-div"><div _ngcontent-qmd-c106="" class="highlight-div-header"><div _ngcontent-qmd-c106="" class="highlight-div-header-left"><div _ngcontent-qmd-c106="" class="handle-button expand-button"><div _ngcontent-qmd-c106="" class="handle-hover-tips">收起</div></div></div><div _ngcontent-qmd-c106="" class="highlight-div-header-right"><div _ngcontent-qmd-c106="" class="handle-button ai-button"></div><div _ngcontent-qmd-c106="" class="handle-button line-button"><div _ngcontent-qmd-c106="" class="handle-hover-tips">自动换行</div></div><div _ngcontent-qmd-c106="" class="handle-button theme-button"><div _ngcontent-qmd-c106="" class="handle-hover-tips">深色代码主题</div></div><div _ngcontent-qmd-c106="" class="handle-button copy-button"><div _ngcontent-qmd-c106="" class="handle-hover-tips">复制</div></div></div></div><div _ngcontent-qmd-c106="" class="highlight-scroll-div"><pre class="cpp prettyprint linenums hljs language-cpp" hw-language="cpp" data-highlighted="yes"><ol class="linenums"><li><span class="hljs-keyword">template</span>&lt;<span class="hljs-keyword">typename</span> aType, <span class="hljs-keyword">typename</span> bType, <span class="hljs-keyword">typename</span> cType, <span class="hljs-keyword">typename</span> biasType&gt; </li><li>__aicore__ <span class="hljs-keyword">inline</span> <span class="hljs-type">void</span> MatmulLeakyKernel&lt;aType, bType, cType, biasType&gt;::<span class="hljs-built_in">Process</span>() </li><li>{ </li><li>    <span class="hljs-comment">// 步骤1：初始化一个MatMul对象，将输入数据从Global Memory搬运到Cube核上。 </span></li><li>    <span class="hljs-type">uint32_t</span> computeRound = <span class="hljs-number">0</span>; </li><li>    <span class="hljs-built_in">REGIST_MATMUL_OBJ</span>(&amp;pipe, <span class="hljs-built_in">GetSysWorkSpacePtr</span>(), matmulObj); </li><li>    matmulObj.<span class="hljs-built_in">Init</span>(&amp;tiling); </li><li>    matmulObj.<span class="hljs-built_in">SetTensorA</span>(aGlobal); </li><li>    matmulObj.<span class="hljs-built_in">SetTensorB</span>(bGlobal); </li><li>    matmulObj.<span class="hljs-built_in">SetBias</span>(biasGlobal); </li><li>     </li><li>    <span class="hljs-keyword">while</span> (matmulObj.<span class="hljs-keyword">template</span> <span class="hljs-built_in">Iterate</span>&lt;<span class="hljs-literal">true</span>&gt;()) { <span class="hljs-comment">// 步骤2：进行MatMul内部的计算。 </span></li><li>        <span class="hljs-comment">// 步骤3：将MatMul的计算结果搬运到Vector核上。 </span></li><li>        reluOutLocal = reluOutQueue_.<span class="hljs-built_in">AllocTensor</span>&lt;cType&gt;(); </li><li>        matmulObj.<span class="hljs-keyword">template</span> <span class="hljs-built_in">GetTensorC</span>&lt;<span class="hljs-literal">true</span>&gt;(reluOutLocal, <span class="hljs-literal">false</span>, <span class="hljs-literal">true</span>); </li><li>       <span class="hljs-comment">// 步骤4：进行Vector矢量计算。 </span></li><li>        AscendC::<span class="hljs-built_in">LeakyRelu</span>(reluOutLocal, reluOutLocal, (cType)alpha, tiling.baseM * tiling.baseN); </li><li>        reluOutQueue_.<span class="hljs-built_in">EnQue</span>(reluOutLocal); </li><li>        <span class="hljs-comment">// 步骤5：将输出结果搬运到Global Memory上 </span></li><li>        reluOutQueue_.<span class="hljs-built_in">DeQue</span>&lt;cType&gt;(); </li><li>        <span class="hljs-comment">// ... </span></li><li>        AscendC::<span class="hljs-built_in">DataCopy</span>(cGlobal[startOffset], reluOutLocal, copyParam); </li><li>        reluOutQueue_.<span class="hljs-built_in">FreeTensor</span>(reluOutLocal); </li><li> </li><li>        computeRound++; </li><li>    } </li><li>    matmulObj.<span class="hljs-built_in">End</span>(); </li><li>}</li></ol></pre></div></div> </div> <div class="tiledSection"><h2 id="section904mcpsimp">编程模型背后的奥秘<i class="anchor-icon anchor-icon-link" anchorid="section904mcpsimp" tips="复制节点链接"></i></h2><p>由上文可知，AscendC的并行编程范式核心要素是：任务并行计算、队列管理通信和同步、自定义任务资源调度。本节介绍编程模型的实现原理，作为扩展阅读，便于开发者更好的理解编程模型的设计思路和优势，对于后续的深度开发也会有所帮助。</p> <p>每个并行任务Stage的编程范式如下。</p> <ol><li>获取Local Memory的内存，调用<a href="https://developer.huawei.com/consumer/cn/doc/harmonyos-guides/cannkit-tque-alloctensor">AllocTensor</a>申请内存，或者从上游队列<a href="https://developer.huawei.com/consumer/cn/doc/harmonyos-guides/cannkit-tque-deque">DeQue</a>一块内存数据。</li><li>完成计算或者数据搬运。</li><li>把上一步处理好的数据调用<a href="https://developer.huawei.com/consumer/cn/doc/harmonyos-guides/cannkit-tque-enque">EnQue</a>入队。</li><li>调用<a href="https://developer.huawei.com/consumer/cn/doc/harmonyos-guides/cannkit-tque-freetensor">FreeTensor</a>释放不再需要的内存。</li></ol> <p>以最简单的矢量编程范式为例，在调用上述接口时，实际上会给各执行单元下发一些指令，如下图所示：</p> <p><span><img height="324.52000000000004" originheight="492" originwidth="787" src="https://alliance-communityfile-drcn.dbankcdn.com/FileServer/getFile/cmtyPub/011/111/111/0000000000011111111.20251211114307.85273863259476109354581699169392:50001231000000:2800:5DF03841451D3C70E888C71DFFD9ED34EC942539249F6F459228D3F9830C613F.png" title="点击放大" width="526.6800000000001"></span></p> </div> <div class="tiledSection"><h3 id="section9488103411113" class="firsth2">EnQue/DeQue处理流程<i class="anchor-icon anchor-icon-link" anchorid="section9488103411113" tips="复制节点链接"></i></h3><ol><li>标量执行单元读取算子指令序列。</li><li>把这些指令发射到对应的执行单元的指令队列。</li><li>各个执行单元并行执行这些指令序列。</li><li>EnQue/DeQue解决对内存的写后读问题。<ul><li>EnQue调用会发射同步指令set，发送信号激活wait。</li><li>DeQue调用会发射同步指令wait，等待数据写入完成。</li><li>wait需要等到set信号才能执行否则阻塞。</li></ul> </li></ol> <p class="msonormal"><span><img height="526.6800000000001" originheight="805" originwidth="806" src="https://alliance-communityfile-drcn.dbankcdn.com/FileServer/getFile/cmtyPub/011/111/111/0000000000011111111.20251211114307.03049918229874732541014600873256:50001231000000:2800:549AD3361749F7386010AE52CB25ED6D1835CFB3FF5EC37B98F63B29BBBE683F.png" title="点击放大" width="526.6800000000001"></span></p> <p>由此可以看出，EnQue/DeQue主要解决了存在数据依赖时，并行执行单元的写后读同步控制问题。</p> <p class="msonormal"><span><img height="143.64000000000001" originheight="216" originwidth="777" src="https://alliance-communityfile-drcn.dbankcdn.com/FileServer/getFile/cmtyPub/011/111/111/0000000000011111111.20251211114307.60415297156848812139292464891914:50001231000000:2800:EDE28D43F4710D2D92D31099D2ABCCEC2DB3615D6C1422E6A0B817E1EDC8C949.png" title="点击放大" width="526.6800000000001"></span></p> </div> <div class="tiledSection"><h3 id="section1381515176129">AllocTensor/FreeTensor处理流程<i class="anchor-icon anchor-icon-link" anchorid="section1381515176129" tips="复制节点链接"></i></h3><ol><li>标量执行单元读取算子指令序列。</li><li>把这些指令发射到对应的执行单元的指令队列。</li><li>各个执行单元并行执行这些指令序列。</li><li>AllocTensor/FreeTensor，解决对内存的读后写问题。<ul><li>AllocTensor调用会发射同步指令wait等待内存被读完成。</li><li>FreeTensor调用会发射同步指令set，通知内存释放，可以重复写。</li><li>wait需要等到set信号才能执行否则阻塞。</li></ul> </li></ol> <p class="msonormal"><span><img height="516.0400000000001" originheight="805" originwidth="815" src="https://alliance-communityfile-drcn.dbankcdn.com/FileServer/getFile/cmtyPub/011/111/111/0000000000011111111.20251211114307.48341400680075223648009937844959:50001231000000:2800:BF220E903D0527B034620AC4D8F1AE149D0244E3C517953332C74D52EF69F1ED.png" title="点击放大" width="526.6800000000001"></span></p> <p>由此可以看出，AllocTensor/FreeTensor主要解决了存在数据依赖时，并行执行单元的读后写同步控制问题。</p> <p class="msonormal"><span><img height="143.64000000000001" originheight="249" originwidth="936" src="https://alliance-communityfile-drcn.dbankcdn.com/FileServer/getFile/cmtyPub/011/111/111/0000000000011111111.20251211114307.36857581898476397232256382277501:50001231000000:2800:2427091843A66ACA5478447652753AF8BFF0416EE118E61CEE8BEB49F0097DBC.png" title="点击放大" width="526.6800000000001"></span></p> <p>通过上文的详细说明，可以看出异步并行程序需要考虑复杂的同步控制，而AscendC编程模型将这些流程进行了封装，同时对外接口通过EnQue/DeQue/AllocTensor/FreeTensor这种开发者熟悉的资源控制方式来体现，同时达到了简化编程和易于理解的目的。</p> </div> </div> <div></div></div>