<h1 _ngcontent-xqc-c119="" class="doc-title ng-star-inserted" title="集成模型"> 集成模型 </h1>

<div _ngcontent-xqc-c106="" auitextselectionexpansion="" class="markdown-body ng-star-inserted" style="position: relative;"> <div><p>模型的加载、编译和推理主要是在native层实现，应用层主要作为数据传递和展示作用。</p> <p class="msonormal">模型推理之前需要对输入数据进行预处理以匹配模型的输入，同样对于模型的输出也需要做处理获取自己期望的结果。另外SDK中提供了设置模型编译和运行时的配置接口，开发者可根据实际需求选择使用接口。</p> <p class="msonormal">本节阐述同步模式下单模型的使用，从流程上分别阐述每个步骤在应用层和native层的实现和调用。接口请参见<a href="https://developer.huawei.com/consumer/cn/doc/harmonyos-references/cannkit" target="_blank">API参考</a>，示例请参见<a href="https://gitcode.com/HarmonyOS_Samples/cannkit-samplecode-clientdemo-cpp" target="_blank">SampleCode</a>，本示例支持加载离线模型对图片中的物体进行分类，App运行效果图如下所示。</p> <p><span><img height="1126.9627320000002" originheight="2832" originwidth="1316" src="https://alliance-communityfile-drcn.dbankcdn.com/FileServer/getFile/cmtyPub/011/111/111/0000000000011111111.20251211114254.66530967253182329119202020900384:50001231000000:2800:5C4039ACCD32F7201DB5D0F3532235A3B9BBE7FBE2EC2E7384313A4BB064D2B7.png" title="点击放大" width="523.6875"></span></p> <div class="tiledSection"><h2 id="section4925101013216">预置模型<i class="anchor-icon anchor-icon-link" anchorid="section4925101013216" tips="复制节点链接"></i></h2><p>为了让App运行时能够读取到模型文件和处理推理结果，需要先把离线模型和模型对应的结果标签文件预置到工程的<span class="filepath">“entry/src/main/resources/rawfile”</span>目录中。</p> <p>本示例所使用的离线模型的转换和生成请参考<a href="https://developer.huawei.com/consumer/cn/doc/harmonyos-guides/cannkit-model-conversion-example#section329315242618">Caffe模型转换</a>。</p> </div> <div class="tiledSection"><h2 id="section1377917334217">加载离线模型<i class="anchor-icon anchor-icon-link" anchorid="section1377917334217" tips="复制节点链接"></i></h2><p>在App应用创建时加载模型和读取结果标签文件。</p> <ol><li><span>调用NAPI层的LoadModel函数，读取模型的buffer。</span></li><li><span>（可选）根据需要调用<a href="https://developer.huawei.com/consumer/cn/doc/harmonyos-references/cannkit#hms_hiaioptions_setomoptions" target="_blank">HMS_HiAIOptions_SetOmOptions</a>接口，打开维测功能（如Profiling）。</span></li><li><span>把模型buffer传递给HIAIModelManager类的HIAIModelManager::LoadModelFromBuffer接口，该接口调用<a href="https://developer.huawei.com/consumer/cn/doc/harmonyos-references/capi-neural-network-core-h#oh_nncompilation_constructwithofflinemodelbuffer" target="_blank">OH_NNCompilation_ConstructWithOfflineModelBuffer</a>创建模型的编译实例。</span></li><li><span>设置模型的deviceID。</span><p></p><div _ngcontent-xqc-c106="" class="highlight-div"><div _ngcontent-xqc-c106="" class="highlight-div-header"><div _ngcontent-xqc-c106="" class="highlight-div-header-left"><div _ngcontent-xqc-c106="" class="handle-button expand-button"><div _ngcontent-xqc-c106="" class="handle-hover-tips">收起</div></div></div><div _ngcontent-xqc-c106="" class="highlight-div-header-right"><div _ngcontent-xqc-c106="" class="handle-button ai-button"></div><div _ngcontent-xqc-c106="" class="handle-button line-button"><div _ngcontent-xqc-c106="" class="handle-hover-tips">自动换行</div></div><div _ngcontent-xqc-c106="" class="handle-button theme-button"><div _ngcontent-xqc-c106="" class="handle-hover-tips">深色代码主题</div></div><div _ngcontent-xqc-c106="" class="handle-button copy-button"><div _ngcontent-xqc-c106="" class="handle-hover-tips">复制</div></div></div></div><div _ngcontent-xqc-c106="" class="highlight-scroll-div"><pre class="cpp prettyprint linenums hljs language-cpp" hw-language="cpp" data-highlighted="yes"><ol class="linenums"><li><span class="hljs-type">size_t</span> deviceID = <span class="hljs-number">0</span>;</li><li><span class="hljs-type">const</span> <span class="hljs-type">size_t</span> *allDevicesID = <span class="hljs-literal">nullptr</span>;</li><li><span class="hljs-type">uint32_t</span> deviceCount = <span class="hljs-number">0</span>;</li><li><span class="hljs-comment">// 获取所有已连接设备的ID</span></li><li>OH_NN_ReturnCode ret = <span class="hljs-built_in">OH_NNDevice_GetAllDevicesID</span>(&amp;allDevicesID, &amp;deviceCount);</li><li><span class="hljs-keyword">if</span> (ret != OH_NN_SUCCESS || allDevicesID == <span class="hljs-literal">nullptr</span>) {</li><li>    <span class="hljs-built_in">OH_LOG_ERROR</span>(LOG_APP, <span class="hljs-string">"OH_NNDevice_GetAllDevicesID failed"</span>);</li><li>    <span class="hljs-keyword">return</span> OH_NN_FAILED;</li><li>}</li><li><span class="hljs-comment">// 获取设备名为HIAI_F的设备ID</span></li><li><span class="hljs-keyword">for</span> (<span class="hljs-type">uint32_t</span> i = <span class="hljs-number">0</span>; i &lt; deviceCount; i++) {</li><li>    <span class="hljs-type">const</span> <span class="hljs-type">char</span> *name = <span class="hljs-literal">nullptr</span>;</li><li>    <span class="hljs-comment">// 获取指定设备的名称</span></li><li>    ret = <span class="hljs-built_in">OH_NNDevice_GetName</span>(allDevicesID[i], &amp;name);</li><li>    <span class="hljs-keyword">if</span> (ret != OH_NN_SUCCESS || name == <span class="hljs-literal">nullptr</span>) {</li><li>        <span class="hljs-built_in">OH_LOG_ERROR</span>(LOG_APP, <span class="hljs-string">"OH_NNDevice_GetName failed"</span>);</li><li>        <span class="hljs-keyword">return</span> OH_NN_FAILED;</li><li>    }</li><li>    <span class="hljs-keyword">if</span> (std::<span class="hljs-built_in">string</span>(name) == <span class="hljs-string">"HIAI_F"</span>) {</li><li>        deviceID = allDevicesID[i];</li><li>        <span class="hljs-keyword">break</span>;</li><li>    }</li><li>}</li><li>
</li><li><span class="hljs-comment">// modelData和modelSize为模型的内存地址和大小， compilation的创建可参考</span><a href="https://developer.huawei.com/consumer/cn/codelabsPortal/carddetails/tutorials_CANNKit-Image-classification" target="_blank"><span class="hljs-comment">CANN Kit Codelab</span></a></li><li>OH_NNCompilation *compilation = <span class="hljs-built_in">OH_NNCompilation_ConstructWithOfflineModelBuffer</span>(modelData, modelSize); </li><li><span class="hljs-comment">// 设置编译器的设备id为HIAI_F</span></li><li>ret = <span class="hljs-built_in">OH_NNCompilation_SetDevice</span>(compilation, deviceID); </li><li><span class="hljs-keyword">if</span> (ret != OH_NN_SUCCESS) {</li><li>    <span class="hljs-built_in">OH_LOG_ERROR</span>(LOG_APP, <span class="hljs-string">"OH_NNCompilation_SetDevice failed"</span>);</li><li>    <span class="hljs-keyword">return</span> OH_NN_FAILED;</li><li>}</li></ol></pre></div></div> <p></p></li><li><span>调用<a href="https://developer.huawei.com/consumer/cn/doc/harmonyos-references/capi-neural-network-core-h#oh_nncompilation_build" target="_blank">OH_NNCompilation_Build</a>，执行模型编译。</span></li><li><span>调用<a href="https://developer.huawei.com/consumer/cn/doc/harmonyos-references/capi-neural-network-core-h#oh_nnexecutor_construct" target="_blank">OH_NNExecutor_Construct</a>，创建模型执行器。</span></li><li><span>调用<a href="https://developer.huawei.com/consumer/cn/doc/harmonyos-references/capi-neural-network-core-h#oh_nncompilation_destroy" target="_blank">OH_NNCompilation_Destroy</a>，释放模型编译实例。</span></li></ol> <p class="msonormal">上述流程可参见<a href="https://gitcode.com/HarmonyOS_Samples/cannkit-samplecode-clientdemo-cpp" target="_blank">SampleCode</a>中<span class="filepath">“entry/src/main/cpp/Classification.cpp”</span>文件中的LoadModel函数和<span class="filepath">“entry/src/main/cpp/HIAIModelManager.cpp”</span>中的HIAIModelManager::LoadModelFromBuffer函数。</p> </div> <div class="tiledSection"><h2 id="section264884843918">输入输出数据准备<i class="anchor-icon anchor-icon-link" anchorid="section264884843918" tips="复制节点链接"></i></h2><ol><li><span>处理模型的输入，例如示例中模型的输入为1*3*227*227格式Float类型的数据，需要把输入的图片转成该格式后传递到NAPI层。</span></li><li><span>创建模型的输入和输出Tensor，并把应用层传递的数据填充到输入的Tensor中。</span><p></p><div _ngcontent-xqc-c106="" class="highlight-div"><div _ngcontent-xqc-c106="" class="highlight-div-header"><div _ngcontent-xqc-c106="" class="highlight-div-header-left"><div _ngcontent-xqc-c106="" class="handle-button expand-button"><div _ngcontent-xqc-c106="" class="handle-hover-tips">收起</div></div></div><div _ngcontent-xqc-c106="" class="highlight-div-header-right"><div _ngcontent-xqc-c106="" class="handle-button ai-button"></div><div _ngcontent-xqc-c106="" class="handle-button line-button"><div _ngcontent-xqc-c106="" class="handle-hover-tips">自动换行</div></div><div _ngcontent-xqc-c106="" class="handle-button theme-button"><div _ngcontent-xqc-c106="" class="handle-hover-tips">深色代码主题</div></div><div _ngcontent-xqc-c106="" class="handle-button copy-button"><div _ngcontent-xqc-c106="" class="handle-hover-tips">复制</div></div></div></div><div _ngcontent-xqc-c106="" class="highlight-scroll-div"><pre class="cpp prettyprint linenums hljs language-cpp" hw-language="cpp" data-highlighted="yes"><ol class="linenums"><li><span class="hljs-comment">// 创建输入数据</span></li><li><span class="hljs-type">size_t</span> inputCount = <span class="hljs-number">0</span>;</li><li>std::vector&lt;NN_Tensor*&gt; inputTensors;</li><li>OH_NN_ReturnCode ret = <span class="hljs-built_in">OH_NNExecutor_GetInputCount</span>(executor, &amp;inputCount); <span class="hljs-comment">// 创建executor可参考</span><a href="https://developer.huawei.com/consumer/cn/codelabsPortal/carddetails/tutorials_CANNKit-Image-classification" target="_blank"><span class="hljs-comment">CANN Kit Codelab</span></a></li><li><span class="hljs-keyword">if</span> (ret != OH_NN_SUCCESS || inputCount != inputData.<span class="hljs-built_in">size</span>()) { <span class="hljs-comment">// inputData为开发者构造的输入数据</span></li><li>    <span class="hljs-built_in">OH_LOG_ERROR</span>(LOG_APP, <span class="hljs-string">"OH_NNExecutor_GetInputCount failed, size mismatch"</span>);</li><li>    <span class="hljs-keyword">return</span> OH_NN_FAILED;</li><li>}</li><li><span class="hljs-keyword">for</span> (<span class="hljs-type">size_t</span> i = <span class="hljs-number">0</span>; i &lt; inputCount; ++i) {</li><li>    NN_TensorDesc *tensorDesc = <span class="hljs-built_in">OH_NNExecutor_CreateInputTensorDesc</span>(executor, i); <span class="hljs-comment">// 创建executor可参考</span><a href="https://developer.huawei.com/consumer/cn/codelabsPortal/carddetails/tutorials_CANNKit-Image-classification" target="_blank"><span class="hljs-comment">CANN Kit Codelab</span></a></li><li>    NN_Tensor *tensor = <span class="hljs-built_in">OH_NNTensor_Create</span>(deviceID, tensorDesc); <span class="hljs-comment">// deviceID的获取方式可参考</span><a href="/consumer/cn/doc/harmonyos-guides/cannkit-integration-model#section1377917334217"><span class="hljs-comment">加载离线模型</span></a><span class="hljs-comment">的步骤3或者</span><a href="https://developer.huawei.com/consumer/cn/codelabsPortal/carddetails/tutorials_CANNKit-Image-classification" target="_blank"><span class="hljs-comment">CANN Kit Codelab</span></a></li><li>    <span class="hljs-keyword">if</span> (tensor != <span class="hljs-literal">nullptr</span>) {</li><li>        inputTensors.<span class="hljs-built_in">push_back</span>(tensor);</li><li>    }</li><li>    <span class="hljs-built_in">OH_NNTensorDesc_Destroy</span>(&amp;tensorDesc);</li><li>}</li><li><span class="hljs-keyword">if</span> (inputTensors.<span class="hljs-built_in">size</span>() != inputCount) {</li><li>    <span class="hljs-built_in">OH_LOG_ERROR</span>(LOG_APP, <span class="hljs-string">"input size mismatch"</span>);</li><li>    <span class="hljs-built_in">DestroyTensors</span>(inputTensors); <span class="hljs-comment">// DestroyTensors为释放tensor内存操作函数，具体实现可参考</span><a href="https://developer.huawei.com/consumer/cn/codelabsPortal/carddetails/tutorials_CANNKit-Image-classification" target="_blank"><span class="hljs-comment">CANN Kit Codelab</span></a></li><li>    <span class="hljs-keyword">return</span> OH_NN_FAILED;</li><li>}</li><li>
</li><li><span class="hljs-comment">// 初始化输入数据</span></li><li><span class="hljs-keyword">for</span> (<span class="hljs-type">size_t</span> i = <span class="hljs-number">0</span>; i &lt; inputTensors.<span class="hljs-built_in">size</span>(); ++i) {</li><li>    <span class="hljs-type">void</span> *data = <span class="hljs-built_in">OH_NNTensor_GetDataBuffer</span>(inputTensors[i]);</li><li>    <span class="hljs-type">size_t</span> dataSize = <span class="hljs-number">0</span>;</li><li>    <span class="hljs-built_in">OH_NNTensor_GetSize</span>(inputTensors[i], &amp;dataSize);</li><li>    <span class="hljs-keyword">if</span> (data == <span class="hljs-literal">nullptr</span> || dataSize != inputData[i].<span class="hljs-built_in">size</span>()) { <span class="hljs-comment">// inputData为模型的输入数据，使用方式可参考</span><a href="https://developer.huawei.com/consumer/cn/codelabsPortal/carddetails/tutorials_CANNKit-Image-classification" target="_blank"><span class="hljs-comment">CANN Kit Codelab</span></a></li><li>        <span class="hljs-built_in">OH_LOG_ERROR</span>(LOG_APP, <span class="hljs-string">"invalid data or dataSize"</span>);</li><li>        <span class="hljs-keyword">return</span> OH_NN_FAILED;</li><li>    }</li><li>    <span class="hljs-built_in">memcpy</span>(data, inputData[i].<span class="hljs-built_in">data</span>(), inputData[i].<span class="hljs-built_in">size</span>()); <span class="hljs-comment">// inputData为模型的输入数据，使用方式可参考</span><a href="https://developer.huawei.com/consumer/cn/codelabsPortal/carddetails/tutorials_CANNKit-Image-classification" target="_blank"><span class="hljs-comment">CANN Kit Codelab</span></a></li><li>}</li><li>
</li><li><span class="hljs-comment">// 创建输出数据，与输入数据的创建方式类似</span></li><li><span class="hljs-type">size_t</span> outputCount = <span class="hljs-number">0</span>;</li><li>std::vector&lt;NN_Tensor*&gt; outputTensors;</li><li>ret = <span class="hljs-built_in">OH_NNExecutor_GetOutputCount</span>(executor, &amp;outputCount); <span class="hljs-comment">// 创建executor可参考</span><a href="https://developer.huawei.com/consumer/cn/codelabsPortal/carddetails/tutorials_CANNKit-Image-classification" target="_blank"><span class="hljs-comment">CANN Kit Codelab</span></a></li><li><span class="hljs-keyword">if</span> (ret != OH_NN_SUCCESS) {</li><li>    <span class="hljs-built_in">OH_LOG_ERROR</span>(LOG_APP, <span class="hljs-string">"OH_NNExecutor_GetOutputCount failed"</span>);</li><li>    <span class="hljs-built_in">DestroyTensors</span>(inputTensors); <span class="hljs-comment">// DestroyTensors为释放tensor内存操作函数，具体实现可参考</span><a href="https://developer.huawei.com/consumer/cn/codelabsPortal/carddetails/tutorials_CANNKit-Image-classification" target="_blank"><span class="hljs-comment">CANN Kit Codelab</span></a></li><li>    <span class="hljs-keyword">return</span> OH_NN_FAILED;</li><li>}</li><li><span class="hljs-keyword">for</span> (<span class="hljs-type">size_t</span> i = <span class="hljs-number">0</span>; i &lt; outputCount; i++) {</li><li>    NN_TensorDesc *tensorDesc = <span class="hljs-built_in">OH_NNExecutor_CreateOutputTensorDesc</span>(executor, i); <span class="hljs-comment">// 创建executor可参考</span><a href="https://developer.huawei.com/consumer/cn/codelabsPortal/carddetails/tutorials_CANNKit-Image-classification" target="_blank"><span class="hljs-comment">CANN Kit Codelab</span></a></li><li>    NN_Tensor *tensor = <span class="hljs-built_in">OH_NNTensor_Create</span>(deviceID, tensorDesc); <span class="hljs-comment">// deviceID的获取方式可参考</span><a href="/consumer/cn/doc/harmonyos-guides/cannkit-integration-model#section1377917334217"><span class="hljs-comment">加载离线模型</span></a><span class="hljs-comment">的步骤3或者</span><a href="https://developer.huawei.com/consumer/cn/codelabsPortal/carddetails/tutorials_CANNKit-Image-classification" target="_blank"><span class="hljs-comment">CANN Kit Codelab</span></a></li><li>    <span class="hljs-keyword">if</span> (tensor != <span class="hljs-literal">nullptr</span>) {</li><li>        outputTensors.<span class="hljs-built_in">push_back</span>(tensor);</li><li>    }</li><li>    <span class="hljs-built_in">OH_NNTensorDesc_Destroy</span>(&amp;tensorDesc);</li><li>}</li><li><span class="hljs-keyword">if</span> (outputTensors.<span class="hljs-built_in">size</span>() != outputCount) {</li><li>    <span class="hljs-built_in">DestroyTensors</span>(inputTensors); <span class="hljs-comment">// DestroyTensors为释放tensor内存操作函数，具体实现可参考</span><a href="https://developer.huawei.com/consumer/cn/codelabsPortal/carddetails/tutorials_CANNKit-Image-classification" target="_blank"><span class="hljs-comment">CANN Kit Codelab</span></a></li><li>    <span class="hljs-built_in">DestroyTensors</span>(outputTensors); <span class="hljs-comment">// DestroyTensors为释放tensor内存操作函数，具体实现可参考</span><a href="https://developer.huawei.com/consumer/cn/codelabsPortal/carddetails/tutorials_CANNKit-Image-classification" target="_blank"><span class="hljs-comment">CANN Kit Codelab</span></a></li><li>    <span class="hljs-built_in">OH_LOG_ERROR</span>(LOG_APP, <span class="hljs-string">"output size mismatch"</span>);</li><li>    <span class="hljs-keyword">return</span> OH_NN_FAILED;</li><li>}</li></ol></pre></div></div> <p></p></li></ol> <p>上述流程可参见<a href="https://gitcode.com/HarmonyOS_Samples/cannkit-samplecode-clientdemo-cpp" target="_blank">SampleCode</a>中<span class="filepath">“entry/src/main/cpp/Classification.cpp”</span>文件中的InitIOTensors函数和<span class="filepath">“entry/src/main/cpp/HiAiModelManager.cpp”</span>中的HIAIModelManager::InitIOTensors函数。</p> </div> <div class="tiledSection"><h2 id="section116498481735">同步推理离线模型<i class="anchor-icon anchor-icon-link" anchorid="section116498481735" tips="复制节点链接"></i></h2><div><div class="hw-editor-tip info"><div class="title">说明</div><div class="content"><p>如果不更换模型，则首次编译加载完成后可多次推理，即一次编译加载，多次推理。</p> </div></div></div> </div> <p>调用<a href="https://developer.huawei.com/consumer/cn/doc/harmonyos-references/capi-neural-network-core-h#oh_nnexecutor_runsync" target="_blank">OH_NNExecutor_RunSync</a>，完成模型的同步推理。</p> <p>可参见<a href="https://gitcode.com/HarmonyOS_Samples/cannkit-samplecode-clientdemo-cpp" target="_blank">SampleCode</a>中<span class="filepath">“entry/src/main/cpp/Classification.cpp”</span>文件中的RunModel函数和<span class="filepath">“entry/src/main/cpp/HiAiModelManager.cpp”</span>中的HIAIModelManager::RunModel函数。</p> <div class="tiledSection"><h2 id="section11415134811811">模型输出后处理<i class="anchor-icon anchor-icon-link" anchorid="section11415134811811" tips="复制节点链接"></i></h2><ol><li><span>调用<a href="https://developer.huawei.com/consumer/cn/doc/harmonyos-references/capi-neural-network-core-h#oh_nntensor_getdatabuffer" target="_blank">OH_NNTensor_GetDataBuffer</a>，获取输出的Tensor，在输出Tensor中会得到模型的输出数据。</span></li><li><span>对输出数据进行相应的处理可得到期望的结果。</span><p></p><p>例如本示例demo中模型的输出是1000个label的概率，期望得到这1000个结果中概率最大的三个标签。</p> <p></p></li><li><span><a href="https://developer.huawei.com/consumer/cn/doc/harmonyos-guides/cannkit-model-inference#li172172195213">销毁申请的Tensor资源和执行器实例</a>。</span></li></ol> <p>上述流程可参见<a href="https://gitcode.com/HarmonyOS_Samples/cannkit-samplecode-clientdemo-cpp" target="_blank">SampleCode</a>中<span class="filepath">“entry/src/main/cpp/Classification.cpp”</span>文件中的GetResult、UnloadModel函数和<span class="filepath">“entry/src/main/cpp/HiAiModelManager.cpp”</span>中的HIAIModelManager::GetResult、HIAIModelManager::UnloadModel函数。</p> </div> <div><div class="hw-editor-tip info"><div class="title">说明</div><div class="content"><p>开发者可根据需要自行设置模型推理优先级。使用<a href="https://developer.huawei.com/consumer/cn/doc/harmonyos-references/capi-neural-network-core-h#oh_nncompilation_setpriority" target="_blank">OH_NNCompilation_SetPriority</a>接口，默认值为OH_NN_PRIORITY_NONE，本接口应在模型推理前调用。</p> </div></div></div> </div> <div></div></div>